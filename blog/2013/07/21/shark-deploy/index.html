
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Shark安装部署与应用 - Data Talks</title>
  <meta name="author" content="Zhu Guangbin">

  
  <meta name="description" content="在搭建部署Spark之后，我们又引入了Shark，一个基于Spark的SQL引擎来替换Hive作为adhoc query engine。我的这篇博客对Shark有简单的介绍。 我们引入Shark是希望利用Spark的性能，提高Hive的执行效率，提供adhoc的interactive的快速查询， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://zhuguangbin.github.io/blog/2013/07/21/shark-deploy">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Data Talks" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Data Talks</a></h1>
  
    <h2>Play with Hadoop/Hive/HBase/Spark/Shark</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:zhuguangbin.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Shark安装部署与应用</h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-21T23:07:00+08:00" pubdate data-updated="true">Jul 21<span>st</span>, 2013</time>
        
      </p>
    
  </header>


<div class="entry-content"><p>  在搭建部署Spark之后，我们又引入了<a href="https://github.com/amplab/shark/wiki">Shark</a>，一个基于Spark的SQL引擎来替换Hive作为adhoc query engine。我的<a href="http://zhuguangbin.github.io/blog/2013/07/09/shark-introduction/">这篇博客</a>对Shark有简单的介绍。
  我们引入Shark是希望利用Spark的性能，提高Hive的执行效率，提供adhoc的interactive的快速查询，并与Spark集成访问Shark的表数据做一些interative算法比如Machine Learning。这样我们的在Hadoop上的任务可以分为以下几类：</p>

<ol>
<li> Batch Job：如ETL，全量历史记录数据处理与统计等等，采用MapReduce Job或者Hive Job。</li>
<li> Adhoc Query：如ba的报表统计，销售人员的临时查询等等，采用Shark Job。</li>
<li> Interative Job：如算法组的个性化推荐，采用Shark或者Spark Job。</li>
<li> Streaming Job：如实时推荐，采用Storm或者Spark-Streaming。</li>
</ol>


<p>  本篇首先介绍Shark的安装部署配置，然后介绍我们在将Shark集成到我们的Hadoop集群中遇到的一些坑和我们的解决方案。</p>

<h3>版本选择</h3>

<ul>
<li>Hadoop: 1.0.3</li>
<li>Hive: 0.9.0 amp-patched version</li>
<li>Spark: 0.7.3</li>
<li>Shark: 0.7.0</li>
</ul>


<blockquote><p>Note: Shark 0.7.0依赖的Hive版本是amplab自己基于apache官方0.9.0版本打过自己的patch的<a href="https://github.com/amplab/hive/tree/amp-0.9-20130517">版本</a>，而我们自己的<a href="https://github.com/dianping/hive/tree/cosmos-hadoop-0.9.0">cosmos-hadoop-0.9.0版本</a>也是基于apache官方0.9.0修复而来。将amp的版本与我们的版本compare了一下(github的<a href="https://github.com/amplab/hive/compare/dianping:cosmos-hadoop-0.9.0...amp-0.9-20130517">compare url</a>)，发现amplab的版本与我们的版本的主要区别在于我们的HiveServer是支持Security的，而amplab的不支持。所以Shark v0.7.0的Hive Server不支持Security。
我们后续会将Shark对Hive的依赖迁移到我们的cosmos-hadoop-0.9.0版本。</p></blockquote>

<h3>前提条件</h3>

<ol>
<li> 集群部署并配置好Hadoop和Spark</li>
<li> 安装部署并配置好Hive</li>
</ol>


<h3>安装配置</h3>

<p>  Shark的安装配置很简单，只需要下载安装包解压并进行简单的配置即可。<em>Note：注意hive的依赖</em></p>

<ol>
<li><p>download Shark和amp-patched hive的压缩包，并解压</p>

<pre><code> cd /usr/local/spark
 wget http://spark-project.org/download-hive-0.9.0-bin.tar.tz
 tar zxvf download-hive-0.9.0-bin.tar.tz
 wget http://spark-project.org/download/shark-0.7.0-hadoop1-bin.tgz
 tar zxvf shark-0.7.0-hadoop1-bin.tgz
 ln -s shark-0.7.0 shark-release

 ls -l
 总用量 82924
 drwxr-xr-x  7 hadoop hadoop     4096 7月  20 16:42 hive-0.9.0-bin
 -rw-r--r--  1 hadoop hadoop 22711471 10月 15 2012 hive-0.9.0-bin.tar.gz
 drwxr-xr-x 11 hadoop hadoop     4096 7月   3 17:53 shark-0.7.0
 lrwxrwxrwx  1 hadoop hadoop       11 7月  14 16:02 shark-release -&gt; shark-0.7.0
 drwxr-xr-x 18 hadoop hadoop     4096 7月  20 17:09 spark-0.7.3
 -rw-r--r--  1 hadoop hadoop 62187714 7月  17 05:29 spark-0.7.3-prebuilt-hadoop1.tgz
 lrwxrwxrwx  1 hadoop hadoop       11 7月  20 16:49 spark-release -&gt; spark-0.7.3
</code></pre></li>
<li><p>配置Shark:</p>

<ul>
<li><p>添加环境变量，如下：</p>

<pre><code>  vim /etc/profile
  export SHARK_HOME=/usr/local/spark/shark-release
  export PATH=$SHARK_HOME/bin:$PATH
</code></pre></li>
<li><p>配置Shark：Shark的配置文件只有一个:$SHARK_HOME/conf/shark-env.sh</p>

<pre><code>  export SPARK_MEM=4g

   # (Required) Set the master program's memory
  export SHARK_MASTER_MEM=1g

   # (Required) Point to your Scala installation.
  export SCALA_HOME=/usr/local/scala/

   # (Required) Point to the patched Hive binary distribution
  export HIVE_HOME=/usr/local/spark/hive-0.9.0-bin

   # (Optional) Specify the location of Hive's configuration directory. By default,
   # it points to $HIVE_HOME/conf
  export HIVE_CONF_DIR="$HIVE_HOME/conf"

   # For running Shark in distributed mode, set the following:
  export HADOOP_HOME=/usr/local/hadoop/hadoop-release/
  export SPARK_HOME=/usr/local/spark/spark-release/
  export MASTER=spark://10.2.6.152:7077

  source $SPARK_HOME/conf/spark-env.sh

   # LZO compression native lib
  export LD_LIBRARY_PATH=/usr/local/hadoop/lzo/lib

   # (Optional) Extra classpath
  export SPARK_LIBRARY_PATH=/usr/local/hadoop/hadoop-release/lib/native/Linux-amd64-64

   # Java options
   # On EC2, change the local.dir to /mnt/tmp
  SPARK_JAVA_OPTS="-Dspark.local.dir=/tmp "
  SPARK_JAVA_OPTS+="-Dspark.kryoserializer.buffer.mb=10 "
   #SPARK_JAVA_OPTS+="-verbose:gc -XX:-PrintGCDetails -XX:+PrintGCTimeStamps "
  SPARK_JAVA_OPTS+="-XX:MaxPermSize=256m "
  SPARK_JAVA_OPTS+="-Dspark.cores.max=12 "
  export SPARK_JAVA_OPTS
</code></pre></li>
</ul>
</li>
<li><p>将Shark以及Hive的安装配置分发到Spark集群的各个节点</p>

<blockquote><p>NOTE：Shark只是一个Client Driver将SQL转化成Spark Job，为什么需要将Shark和Hive的包分发到各个节点呢？其实这样做的目的是将Shark和Hive的jar包加载到Spark StandaloneBackEnd的CLASSPATH里，让Executor启动时加载Shark和Hive的jar包。我尝试不分发Shark和Hive的包，而只将Hive的jar包放到Spark的lib目录下，同样work，否则会包ClassNotFound错误。为了更加方便的管理，还是将Spark和Hive的包分发到各个节点上。</p></blockquote></li>
<li><p>将客户端的Hive换为我们版本的Hive，修改shark-env.sh，将HIVE_HOME只向我们版本的Hive</p>

<pre><code> export HIVE_HOME=/usr/local/hadoop/hive-release
</code></pre>

<blockquote><p>NOTE: 为什么这样做？因为Shark也只是个客户端而已，我们版本的Hive添加了我们自己的一些特性，如比权限验证，我们不允许用户有grant权限，不允许用户set一些重要的HiveConf。而这些是amp的hive没有的。因此，客户端指向我们自己的Hive，而各个节点用amplab的版本就可以。</p></blockquote></li>
<li><p>测试验证：</p>

<pre><code> [hadoop@cosmos155 conf]$ shark

 Starting the Shark Command Line Client
 WARNING: org.apache.hadoop.metrics.jvm.EventCounter is deprecated. Please use org.apache.hadoop.log.metrics.EventCounter in all the log4j.properties files.
 Logging initialized using configuration in jar:file:/usr/local/hadoop/hive-0.9.0/lib/hive-common-0.9.0.jar!/hive-log4j.properties
 Hive history file=/data/hive-query-log/hadoop/hive_job_log_hadoop_201307221453_1130459904.txt
 shark (default)&gt; show tables;
 OK
 device_permanent_city
 dpmid_dp_shop_his_2012
 dpmid_tg_receipt_add
 dpods_mc_table_info
 hippolog
 hippolog_input_nosort
 hippolog_input_sort
 hippologcurrent
 jinss_test_1129
 lzo_rcfile_test
 nginx
 nginx_bak
 nginx_search_condition
 nginx_temp
 nginxlogcurrent
 nginxlogcurrenttmp
 range_keys
 rcfilenginx_gz
 search_log
 searchexec
 test
 Time taken: 3.03 seconds
 shark&gt; 
</code></pre></li>
</ol>


<h3>我们遇到的一些坑</h3>

<ol>
<li><p>Security问题：</p>

<ul>
<li><p>描述：由于我们的Hadoop集群启用了kerberos认证，而Spark目前是不支持Kerberos的，所以，访问HDFS时报如下错误：</p>

<pre><code>  javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]  
</code></pre></li>
<li><p>解决方案：为每一个Spark节点创建一个principal: shark/_HOST@DIANPING.COM，并生成keytab。将shark加入所有组，使其有所有表的读权限。然后，起一个crontab定时执行kinit去KDC拿一张票，保证Spark在向HDFS读取文件时有shark的ticket cache。</p></li>
</ul>
</li>
<li><p>文件权限问题：</p>

<ul>
<li>描述：基于上一个问题的解决方案，这样客户端提交SQL的用户principal是用户自己，如guangbin.zhu，其为本次Job创建了一个scrachdir(/tmp/hive-guangbin.zhu/{jobname})，owner是guangbin.zhu，group是guangbin.zhu的group:op。但发到Spark集群真正执行处理的principal是shark，这样就导致shark用户无权访问guangbin.zhu的scrachdir而报错。</li>
<li>解决方案：在shark启动时，set dfs.umaskmode=000，在Spark集群的hive-site.xml中也添加dfs.umaskmode=000配置。这样强制将本次Shark Job的hdfs的权限设为每个人都有权限读写。</li>
</ul>
</li>
<li><p>并发问题：</p>

<ul>
<li>描述：目前Spark Standalone模式只支持FIFO调度，默认每个Job会占有所有的集群资源，而后续的Job会一直等待直到它退出。这将影响集群多用户的使用，当一个用户执行shark时，其他人只能等待他执行完。</li>
<li><p>解决方案：通过查看文档，Spark支持用户配置其使用的cpu core数，通过以下配置，限定每个shark job的资源占用：</p>

<pre><code>  #每个Spark Job的Worker Executor使用4G内存
  export SPARK_MEM=4g
  #每个Spark Job最大占用12个CPU core
  SPARK_JAVA_OPTS+="-Dspark.cores.max=12 "
</code></pre></li>
</ul>
</li>
<li><p>权限问题：</p>

<ul>
<li>描述：我们的Hive启用了authorization，而shark v0.7.0中没有authorization，即所有人对所有表拥有所有权限，这不符合我们的需求。</li>
<li>解决方案：修改代码，修复bug，见<a href="https://github.com/zhuguangbin/shark/commit/93aa994db81512d4bfe6bee6a94cc198f6970fde">github commit</a></li>
</ul>
</li>
</ol>


<blockquote><p>Note: 在build Shark时，一定要选择amplab patched的HIVE_HOME，否则build出来的shark的SharkSemanticAnalyzer会有问题。我们后续将对Hive的依赖迁移到我们的Hive版本。</p></blockquote>

<h3>参考资料</h3>

<ol>
<li><a href="https://github.com/amplab/shark">shark on github</a></li>
<li><a href="https://github.com/amplab/shark/wiki">shark 官方wiki</a></li>
<li><a href="http://ampcamp.berkeley.edu/wp-content/uploads/2013/02/Shark-SQL-and-Rich-Analytics-at-Scala-Reynold-Xin.pdf">shark introductin slide</a></li>
</ol>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Zhu Guangbin</span></span>

      








  


<time datetime="2013-07-21T23:07:00+08:00" pubdate data-updated="true">Jul 21<span>st</span>, 2013</time>
      


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://zhuguangbin.github.io/blog/2013/07/21/shark-deploy/" data-via="" data-counturl="http://zhuguangbin.github.io/blog/2013/07/21/shark-deploy/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2013/07/16/spark-programming-examples/" title="Previous Post: Spark Programming Examples">&laquo; Spark Programming Examples</a>
      
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/07/21/shark-deploy/">Shark安装部署与应用</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/16/spark-programming-examples/">Spark Programming Examples</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/16/spark-programming-user-guide-for-javauser/">Spark Programming User Guide for Java User</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/16/spark-programming-user-guide-for-scalauser/">Spark Programming User Guide for Scala User</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/16/spark-programming-user-guide-basic/">Spark Programming User Guide Basic</a>
      </li>
    
  </ul>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Zhu Guangbin -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
