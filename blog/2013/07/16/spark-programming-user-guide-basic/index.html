
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Spark Programming User Guide Basic - Data Talks</title>
  <meta name="author" content="Zhu Guangbin">

  
  <meta name="description" content="开发环境搭建 开发Spark最便捷的方式就是利用spark-shell，交互式编程。参考安装部署篇本地模式，在本地部署好Spark，打开spark-shell即可。 另一种方式是在自己的project中引用spark的包，开发standalone的Spark Job。用户可以选择自己喜欢的构建工具 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://zhuguangbin.github.io/blog/2013/07/16/spark-programming-user-guide-basic/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Data Talks" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:zhuguangbin.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
    <li><a href="/">
        <span class="blue_light">
            Data Talks
        </span>
       
           <span class="blue_dark">
             Play with Hadoop/Hive/HBase/Spark/Shark
           </span>
       
    </a></li>
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about">About me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Spark Programming User Guide Basic</h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-16T16:27:00+08:00" pubdate data-updated="true">Jul 16<span>th</span>, 2013</time>
        
      </p>
    
  </header>


<div class="entry-content"><h3>开发环境搭建</h3>

<p>  开发Spark最便捷的方式就是利用spark-shell，交互式编程。参考<a href="http://localhost:4000/blog/2013/07/16/spark-deploy/">安装部署篇</a>本地模式，在本地部署好Spark，打开spark-shell即可。</p>

<p>  另一种方式是在自己的project中引用spark的包，开发standalone的Spark Job。用户可以选择自己喜欢的构建工具（sbt/maven etc），构建一个Scala Project，只需要引入spark的包即可。推荐采用sbt构建项目，用eclipse的scala-ide进行开发。下节简单介绍一个简单的SparkHelloWorld项目的构建和开发步骤。</p>

<h3>创建第一个SparkHelloWorld Project</h3>

<ol>
<li> 安装sbt： 请参考<a href="http://www.scala-sbt.org/release/docs/Getting-Started/Setup.html">这里</a>安装sbt，不在此赘述</li>
<li> 添加sbteclipse插件。sbteclipse插件用来生成eclipse project，请参考<a href="https://github.com/typesafehub/sbteclipse">这里</a>配置。</li>
<li> 安装eclipse scala-ide插件：update site 地址在<a href="http://scala-ide.org/download/current.html">这里</a>。    <em>Note：由于Spark是基于Scala 2.9.3构建的，请选择2.9.</em>版本安装*</li>
<li><p> 构建第一个SparkHelloWorld项目：</p>

<pre><code>hadoop@Aspire-5830TG:~/project/workspace$ mkdir SparkHelloWorld
hadoop@Aspire-5830TG:~/project/workspace$ cd SparkHelloWorld/
hadoop@Aspire-5830TG:~/project/workspace/SparkHelloWorld$ ll
总用量 0
#编辑build.sbt，添加spark-core依赖
hadoop@Aspire-5830TG:~/project/workspace/SparkHelloWorld$ vim build.sbt
name := "SparkHelloWorld"
version := "1.0"
scalaVersion := "2.9.3"
libraryDependencies += "org.spark-project" %% "spark-core" % "0.7.3"
resolvers ++= Seq(
  "Akka Repository" at "http://repo.akka.io/releases/",
  "Spray Repository" at "http://repo.spray.cc/")
#构建eclipse project
hadoop@Aspire-5830TG:~/project/workspace/SparkHelloWorld$ sbt eclipse
[info] Loading global plugins from /home/hadoop/.sbt/plugins
[info] Set current project to SparkHelloWorld (in build file:/home/hadoop/project/  workspace/SparkHelloWorld/)
[info] About to create Eclipse project files for your project(s).
[info] Updating {file:/home/hadoop/project/workspace/SparkHelloWorld/}default-fa0ba0...
[info] Resolving commons-lang#commons-lang;2.6 ...
[info] Done updating.
[info] Successfully created Eclipse project files for project(s):
[info] SparkHelloWorld
hadoop@Aspire-5830TG:~/project/workspace/SparkHelloWorld$ ll -a
总用量 40
 4 drwxrwxr-x  5 hadoop hadoop  4096  7月 21 16:18 .
 4 drwxrwxr-x 40 hadoop hadoop  4096  7月 21 16:13 ..
 4 -rw-rw-r--  1 hadoop hadoop   264  7月 21 16:17 build.sbt
12 -rw-rw-r--  1 hadoop hadoop 10903  7月 21 16:17 .classpath
 4 drwxrwxr-x  3 hadoop hadoop  4096  7月 21 16:17 project
 4 -rw-rw-r--  1 hadoop hadoop   369  7月 21 16:17 .project
 4 drwxrwxr-x  4 hadoop hadoop  4096  7月 21 16:17 src
 4 drwxrwxr-x  5 hadoop hadoop  4096  7月 21 16:17 target
hadoop@Aspire-5830TG:~/project/workspace/SparkHelloWorld$ 
</code></pre></li>
<li><p> 导入eclipse。<br/>
<img src="/images/sparkhelloworld_eclipse_project.png" alt="SparkHelloWorld eclipse project " /></p></li>
<li><p> 创建第一个SparkHelloWorld Job</p>

<pre><code>import spark.SparkContext
import spark.SparkContext._
object SparkHelloWorld {
def main(args: Array[String]): Unit = {

    val sc = new SparkContext("local","SparkHelloWorld","/usr/local/spark/spark-release",List   ("target/scala-2.9.3/sparkhelloworld_2.9.3-1.0.jar"))
    val log = sc.textFile("/var/log/alternatives.log")
    val count = log.count()
    println("log has "+ count + "lines")
  }

}
</code></pre></li>
<li><p> 打包执行</p>

<pre><code>#利用sbt打包
hadoop@Aspire-5830TG:~/project/workspace/SparkHelloWorld$ sbt package
[info] Loading global plugins from /home/hadoop/.sbt/plugins
[info] Set current project to SparkHelloWorld (in build file:/home/hadoop/project/  workspace/SparkHelloWorld/)
[info] Compiling 1 Scala source to /home/hadoop/project/workspace/SparkHelloWorld/target/   scala-2.9.3/classes...
[info] Packaging /home/hadoop/project/workspace/SparkHelloWorld/target/scala-2.9.3/sparkhelloworld_2.9.3-1.0.jar ...
[info] Done packaging.
[success] Total time: 5 s, completed 2013-7-21 16:39:28
#执行
hadoop@Aspire-5830TG:~/project/workspace/SparkHelloWorld$ sbt run
[info] Loading global plugins from /home/hadoop/.sbt/plugins
[info] Set current project to SparkHelloWorld (in build file:/home/hadoop/project/  workspace/SparkHelloWorld/)
[info] Running SparkHelloWorld 
log has 108 lines
13/07/21 16:39:35 INFO network.ConnectionManager: Selector thread was interrupted!
[success] Total time: 3 s, completed 2013-7-21 16:39:35
hadoop@Aspire-5830TG:~/project/workspace/SparkHelloWorld$
</code></pre></li>
<li><p> 发布到集群运行</p></li>
</ol>


<p>  上述示例是在本地执行，如要发布到集群运行，需要将SparkContext中Master的地址修改为集群Master的地址，打包并添加到Spark的CLASSPATH 。如：</p>

<pre><code>    val sc = new SparkContext("*spark://10.2.6.152:7077*","SparkHelloWorld","/usr/local/spark/spark-release",List("target/scala-2.9.3/sparkhelloworld_2.9.3-1.0.jar"))
</code></pre>

<h3>参考资料</h3>

<ol>
<li> <a href="http://spark-project.org/docs/latest/quick-start.html">spark官方文档</a></li>
</ol>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Zhu Guangbin</span></span>

      








  


<time datetime="2013-07-16T16:27:00+08:00" pubdate data-updated="true">Jul 16<span>th</span>, 2013</time>
      


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://zhuguangbin.github.io/blog/2013/07/16/spark-programming-user-guide-basic/" data-via="" data-counturl="http://zhuguangbin.github.io/blog/2013/07/16/spark-programming-user-guide-basic/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2013/07/16/spark-deploy/" title="Previous Post: Spark安装部署篇">&laquo; Spark安装部署篇</a>
      
      
        <a class="basic-alignment right" href="/blog/2013/07/16/spark-programming-user-guide-for-scalauser/" title="Next Post: Spark Programming User Guide For Scala User">Spark Programming User Guide For Scala User &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/07/23/shark-vs-hive-benchmark-test/">Shark vs Hive Benchmark Test</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/21/shark-deploy/">Shark安装部署与应用</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/16/spark-programming-examples/">Spark Programming Examples</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/16/spark-programming-user-guide-for-javauser/">Spark Programming User Guide For Java User</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/16/spark-programming-user-guide-for-scalauser/">Spark Programming User Guide For Scala User</a>
      </li>
    
  </ul>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Zhu Guangbin -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
